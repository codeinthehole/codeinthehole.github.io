<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>postgres on David Winterbottom</title>
    <link>https://codeinthehole.com/tags/postgres/</link>
    <description>Recent content in postgres on David Winterbottom</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Nov 2017 15:50:04 +0000</lastBuildDate><atom:link href="https://codeinthehole.com/tags/postgres/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Joining between date and timestamp fields in Postgres</title>
      <link>https://codeinthehole.com/tips/joining-between-date-and-datetime-fields-in-postgres/</link>
      <pubDate>Thu, 16 Nov 2017 15:50:04 +0000</pubDate>
      
      <guid>https://codeinthehole.com/tips/joining-between-date-and-datetime-fields-in-postgres/</guid>
      <description>Joining tables on date and timestamp with timezone fields in Postgres1 needs careful handling because of time zones and daylight-saving time.
To illustrate, assume we have two tables:
t1 which has a field of type date and a foreign-key t2_id to t2 which has a field of timestamp with timezone. We want to build SQL queries that join between these two tables with additional date constraints on the join.
Assume the date values in t1 correspond to the Europe/London time zone.</description>
    </item>
    
    <item>
      <title>Using pgbadger with AWS RDS</title>
      <link>https://codeinthehole.com/tips/using-pgbadger-with-aws-rds/</link>
      <pubDate>Tue, 29 Aug 2017 14:08:08 +0100</pubDate>
      
      <guid>https://codeinthehole.com/tips/using-pgbadger-with-aws-rds/</guid>
      <description>There&amp;rsquo;s two non-obvious things to know when starting to use pgbadger with AWS RDS.
First, set:
log_statement = None Don&amp;rsquo;t set this to all as the AWS docs suggest.
Further, don&amp;rsquo;t waste your time trying to add a DB parameter to set log_line_prefix to pgbadger&amp;rsquo;s recommended value: it&amp;rsquo;s not possible1. Instead tell pgbadger about the log format that RDS insists on:
pgbadger -f stderr -p &amp;#39;%t:%r:%u@%d:[%p]:&amp;#39; postgres.log Hope that saves you some time.</description>
    </item>
    
    <item>
      <title>Copying Postgres output into a spreadsheet</title>
      <link>https://codeinthehole.com/tips/copying-postgres-output-into-a-spreadsheet/</link>
      <pubDate>Wed, 02 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://codeinthehole.com/tips/copying-postgres-output-into-a-spreadsheet/</guid>
      <description>I often need to grab information from a Postgres database and paste it into a spreadsheet for sharing with others. Google Sheets needs the pasted data to be tab-separated in order to be correctly split into columns. This isn&amp;rsquo;t the default behaviour for psql but here&amp;rsquo;s how to configure psql&amp;rsquo;s output to get it.
At a psql prompt, switch to unaligned output
=&amp;gt; \a set the field separator to a tab character:</description>
    </item>
    
    <item>
      <title>Backing up Postgres database rows before deleting them</title>
      <link>https://codeinthehole.com/tips/backing-up-database-rows-in-postgres-before-deleting-them/</link>
      <pubDate>Thu, 19 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://codeinthehole.com/tips/backing-up-database-rows-in-postgres-before-deleting-them/</guid>
      <description>Hmmm, this delete statement is taking longer than I thought it would&amp;hellip;
If you ever have to manually run a SQL delete statement in psql, you can back-up the rows you&amp;rsquo;re about to delete:
\copy ( select * from $table where id in ( ... ) ) to &amp;#39;/tmp/backup.csv&amp;#39; and, if you&amp;rsquo;ve got your filter clause wrong (we&amp;rsquo;ve all done it), restore them with:
\copy $table from &amp;#39;/tmp/backup.csv&amp;#39; Moderately useful.</description>
    </item>
    
    <item>
      <title>Dumping and restoring a PostGIS database</title>
      <link>https://codeinthehole.com/tips/dumping-and-restoring-a-postgis-database/</link>
      <pubDate>Sun, 28 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://codeinthehole.com/tips/dumping-and-restoring-a-postgis-database/</guid>
      <description>I wasted at least twenty minutes getting this to work. These are my notes.
Problem You are using a PostGIS database and want to take a backup copy from production and restore it in a different environment. One complication is that each environment connects to its database with its own user.
This is a common scenario if you are using GeoDjango.
Solution Suppose your production database is called &amp;ldquo;myproject_prod&amp;rdquo; which you connect to with user &amp;ldquo;myproject_prod_role&amp;rdquo; and you want to replace your existing stage database &amp;ldquo;myproject_stage&amp;rdquo; that you connect to with user &amp;ldquo;myproject_stage_role&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Altering Postgres table columns with South</title>
      <link>https://codeinthehole.com/tips/altering-postgres-table-columns-with-south/</link>
      <pubDate>Tue, 19 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://codeinthehole.com/tips/altering-postgres-table-columns-with-south/</guid>
      <description>Problem You&amp;rsquo;re using Postgres with Django.
You change a field type of one of your models, generate an --auto South migration and attempt to run it. However, South chokes on the new migration complaining that the data in the column cannot be cast to the new type.
For instance, I recently changed a CharField to a TimeField but the corresponding migration lead to:
Running migrations for stores: - Migrating forwards to 0009_auto__chg_field_openingperiod_start__chg_field_openingperiod_end.</description>
    </item>
    
    <item>
      <title>Configuring logging for Postgres.app</title>
      <link>https://codeinthehole.com/tips/configuring-logging-for-postgresapp/</link>
      <pubDate>Mon, 14 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>https://codeinthehole.com/tips/configuring-logging-for-postgresapp/</guid>
      <description>Problem You&amp;rsquo;re using Postgres.app on a Mac for local development but are getting SQL errors from your application. You&amp;rsquo;re seeing an error message:
ERROR: current transaction is aborted, commands ignored until end of transaction block This isn&amp;rsquo;t useful: you want to know which query is generating the error.
Solution Turn on Postgres logging and watch the log files when the error is generated.
This is done by editing the postgresql.conf config file, whose location can be found from the &amp;ldquo;Server Settings&amp;rdquo; option in the Postgres.</description>
    </item>
    
  </channel>
</rss>
